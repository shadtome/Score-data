{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all of our data for this project\n",
    "We obtained data from transfermarkt, understat, and sofascore.  Each of these are on kaggle, and we personally scraped the data from understat and sofascore and put those on kaggle.\n",
    "\n",
    "- [transfermarkt](https://www.kaggle.com/datasets/davidcariboo/player-scores)\n",
    "- [understat](https://www.kaggle.com/datasets/codytipton/player-stats-per-game-understat)\n",
    "- [sofascore](https://www.kaggle.com/datasets/rafaelmiksianmagaldi/sofascore-data)\n",
    "\n",
    "The below function gets all the kaggle data, does the merging of the data and splits it into train and test data.  You can access all the data in its pure form once you download it all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/cody/.kaggle/kaggle.json'\n",
      "Start Kaggle data downloads\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/cody/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/davidcariboo/player-scores\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/cody/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/codytipton/player-stats-per-game-understat\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/cody/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/rafaelmiksianmagaldi/sofascore-data\n",
      "Done with kaggle data\n",
      " Start Merges\n",
      "Start Merging of the Data\n",
      "Done Merging Transfermarkt and Sofascore\n",
      "Done merging Transfermarkt and Understat\n",
      "Done with Merging Transfermarkt x sofascore and Transfermarkt x understat\n",
      "Done with merging of the data\n",
      "Start making database\n",
      "Create train test splits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import get_data.get_all_data as gad \n",
    "gad.get_data_merge_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Data\n",
    "We have two sets of train and test data, depending on if it has a cutoff point for the minutes played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "train = pd.read_csv('data/main_data/train/train.csv')\n",
    "train_cutoff = pd.read_csv('data/main_data/train/train_cutoff_1000.csv')\n",
    "\n",
    "test = pd.read_csv('data/main_data/test/test.csv')\n",
    "test_cutoff = pd.read_csv('data/main_data/test/test_cutoff_1000.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>pos</th>\n",
       "      <th>height</th>\n",
       "      <th>foot</th>\n",
       "      <th>date</th>\n",
       "      <th>market_value</th>\n",
       "      <th>adjusted_market_value</th>\n",
       "      <th>team</th>\n",
       "      <th>league</th>\n",
       "      <th>...</th>\n",
       "      <th>red_card</th>\n",
       "      <th>rating</th>\n",
       "      <th>accuratePass</th>\n",
       "      <th>accurateLongBalls</th>\n",
       "      <th>accurateCross</th>\n",
       "      <th>accurateKeeperSweeper</th>\n",
       "      <th>expectedAssists</th>\n",
       "      <th>expectedGoals</th>\n",
       "      <th>xGChain</th>\n",
       "      <th>xGBuildup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maximilian wittek</td>\n",
       "      <td>1995-08-20</td>\n",
       "      <td>M</td>\n",
       "      <td>173.0</td>\n",
       "      <td>left</td>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>2000000</td>\n",
       "      <td>VfL Bochum 1848</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07479</td>\n",
       "      <td>26.529412</td>\n",
       "      <td>1.966387</td>\n",
       "      <td>1.756303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038472</td>\n",
       "      <td>0.014907</td>\n",
       "      <td>0.028277</td>\n",
       "      <td>0.014541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jovan milosevic</td>\n",
       "      <td>2005-07-30</td>\n",
       "      <td>F</td>\n",
       "      <td>190.0</td>\n",
       "      <td>right</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>VfB Stuttgart</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.94000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tika de jonge</td>\n",
       "      <td>2003-03-10</td>\n",
       "      <td>M</td>\n",
       "      <td>173.0</td>\n",
       "      <td>right</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>FC Groningen</td>\n",
       "      <td>Eredivisie</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.12000</td>\n",
       "      <td>42.400000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056765</td>\n",
       "      <td>0.036020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cas odenthal</td>\n",
       "      <td>2000-09-25</td>\n",
       "      <td>D</td>\n",
       "      <td>190.0</td>\n",
       "      <td>right</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>755054</td>\n",
       "      <td>NEC Nijmegen</td>\n",
       "      <td>Eredivisie</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.87000</td>\n",
       "      <td>41.366667</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miguel baeza</td>\n",
       "      <td>2000-03-26</td>\n",
       "      <td>M</td>\n",
       "      <td>177.0</td>\n",
       "      <td>left</td>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>CD Nacional</td>\n",
       "      <td>Liga Portugal Betclic</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.35600</td>\n",
       "      <td>10.380000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013463</td>\n",
       "      <td>0.048262</td>\n",
       "      <td>0.069041</td>\n",
       "      <td>0.017071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name         dob pos  height   foot        date  market_value  \\\n",
       "0  maximilian wittek  1995-08-20   M   173.0   left  2024-10-19     2000000.0   \n",
       "1    jovan milosevic  2005-07-30   F   190.0  right  2024-01-27      500000.0   \n",
       "2      tika de jonge  2003-03-10   M   173.0  right  2024-10-20      500000.0   \n",
       "3       cas odenthal  2000-09-25   D   190.0  right  2022-04-03      650000.0   \n",
       "4       miguel baeza  2000-03-26   M   177.0   left  2024-09-29      400000.0   \n",
       "\n",
       "   adjusted_market_value             team                 league  ...  \\\n",
       "0                2000000  VfL Bochum 1848             Bundesliga  ...   \n",
       "1                 500000    VfB Stuttgart             Bundesliga  ...   \n",
       "2                 500000     FC Groningen             Eredivisie  ...   \n",
       "3                 755054     NEC Nijmegen             Eredivisie  ...   \n",
       "4                 400000      CD Nacional  Liga Portugal Betclic  ...   \n",
       "\n",
       "   red_card   rating  accuratePass  accurateLongBalls  accurateCross  \\\n",
       "0       0.0  7.07479     26.529412           1.966387       1.756303   \n",
       "1       0.0  3.94000      1.400000           0.000000       0.000000   \n",
       "2       0.0  7.12000     42.400000           3.200000       0.200000   \n",
       "3       0.0  6.87000     41.366667           2.866667       0.066667   \n",
       "4       0.0  6.35600     10.380000           0.540000       0.380000   \n",
       "\n",
       "   accurateKeeperSweeper  expectedAssists  expectedGoals   xGChain  xGBuildup  \n",
       "0                    0.0         0.038472       0.014907  0.028277   0.014541  \n",
       "1                    0.0         0.001434       0.000000  0.000000   0.000000  \n",
       "2                    0.0         0.056765       0.036020  0.000000   0.000000  \n",
       "3                    0.0         0.000000       0.000000  0.000000   0.000000  \n",
       "4                    0.0         0.013463       0.048262  0.069041   0.017071  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of our data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Generalized model class\n",
    "So to make our hyperparameter tuning and for just making models with little effort, we made a generalized regression model that can take its type of model and any parameters needed.\n",
    "\n",
    "There are various classes one can use: in the ensamble_model file:\n",
    "- generalized_Regression\n",
    "    - This is used to make any of the various models with our data with all of the features.\n",
    "- G_Pos, D_Pos, M_Pos, F_Pos, these are inherited classes of generalized_Regression that is specifically designed to only do models on the specific positions.\n",
    "- ensamble_model\n",
    "    - This class is a ensemble of G_Pos, D_Pos, M_Pos, F_Pos, which you can specify the parameters for each of those positions.  This is able to do predictions and fit with the data.  \n",
    "\n",
    "Finally, there are hyperparameter tuning classes that can take these models and go through a random grid search of the parameters to find some optimal parameters for these models.  There is also a beta parameter in these that gives a penatly to the hyperparameter tuning for when they are overfitting.  Specifically, it has the equation\n",
    "    $$ Score = Score_{Test}  + \\beta |Score_{Test} - Score_{Train}| $$\n",
    "\n",
    "This is designed to penalize the models that overfit while going through the hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.main_dataset.ensamble_model as em\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a generalized_Regression model\n",
    "# This gives us a linear regression model\n",
    "ex_LR = em.general_Regression(train,type='LR')\n",
    "\n",
    "#This gives us a linear regression with L2 regularization and regularization factor of 4\n",
    "ex_RIDGE = em.general_Regression(train,type='RIDGE',alpha=4)\n",
    "\n",
    "# This gives us a random forest regression model with the various parameters\n",
    "ex_RFR = em.general_Regression(train,type='RFR',scale='log',max_depth=4,n_estimators=20,min_sample_leaf=2 ,bootstrap=True) \n",
    "\n",
    "# This gives us a Gradient Boost regression model with the various parameters\n",
    "ex_GBR = em.general_Regression(train,type='GBR',scale='log',max_depth=4,n_estimators=20,min_sample_leaf=2 ,bootstrap=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 54376834367966.21 std: 1221604229958.603\n",
      "MSE for test:  mean: 57432157959300.96  std: 11366455370460.338\n",
      "\n",
      "RMSE for train: mean: 7373601.336737566 std: 82690.35510984856\n",
      "RMSE for test: mean: 7537878.749909605 std: 782650.5675984453\n",
      "\n",
      "R^2 for train: mean: 0.41485441920051275 std: 0.004654714636380806\n",
      "R^2 for test: mean: 0.3822597123751495 std: 0.0462619185995481\n",
      "\n",
      "MAE for train: mean: 3719634.1434434974 std: 34014.544478594355\n",
      "MAE for test: mean: 3766498.001722875 std: 181933.56922456858\n",
      "\n",
      "MAPE for train: mean: 4.139587126374417 std: 0.05677865191594086\n",
      "MAPE for test: mean: 4.170831255759044 std: 0.3607062701507288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In each of these, you can perform a cross-validation\n",
    "ex_LR.perform_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 54507743089940.49 std: 1220501912464.027\n",
      "MSE for test:  mean: 57502096779659.27  std: 11424550588100.363\n",
      "\n",
      "RMSE for train: mean: 7382474.783125895 std: 82517.67356602143\n",
      "RMSE for test: mean: 7542120.34204383 std: 786458.8519356432\n",
      "\n",
      "R^2 for train: mean: 0.41344462495224 std: 0.004681733710239646\n",
      "R^2 for test: mean: 0.38156671274494314 std: 0.04724482372464625\n",
      "\n",
      "MAE for train: mean: 3715501.0927937226 std: 33766.96771544349\n",
      "MAE for test: mean: 3760391.087914384 std: 181415.2433834562\n",
      "\n",
      "MAPE for train: mean: 4.140033624748517 std: 0.05671594459387419\n",
      "MAPE for test: mean: 4.170232494477886 std: 0.362505515947886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ex_RIDGE.perform_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 1.2448488409340344 std: 0.02488143613043517\n",
      "MSE for test:  mean: 1.2710089897318997  std: 0.06527437250164449\n",
      "\n",
      "RMSE for train: mean: 1.1156724379004952 std: 0.011128892271941427\n",
      "RMSE for test: mean: 1.1270307054866382 std: 0.028474174653358546\n",
      "\n",
      "R^2 for train: mean: 0.36307950859921334 std: 0.012798513391890573\n",
      "R^2 for test: mean: 0.3494440497312323 std: 0.01350034066792082\n",
      "\n",
      "MAE for train: mean: 0.8845335183106119 std: 0.00875528347034923\n",
      "MAE for test: mean: 0.8934218445317335 std: 0.024553343993494785\n",
      "\n",
      "MAPE for train: mean: 0.0629103073147064 std: 0.0006231763881676812\n",
      "MAPE for test: mean: 0.06353471322828155 std: 0.0016758981716299688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ex_RFR.perform_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 0.5283064512626419 std: 0.008571365662415679\n",
      "MSE for test:  mean: 0.782212511152801  std: 0.054260167671448194\n",
      "\n",
      "RMSE for train: mean: 0.7268230538443737 std: 0.005890641983721369\n",
      "RMSE for test: mean: 0.8839069210075863 std: 0.030349071611655808\n",
      "\n",
      "R^2 for train: mean: 0.7297053670628653 std: 0.0037183401775102917\n",
      "R^2 for test: mean: 0.5989917277083427 std: 0.030790894628957625\n",
      "\n",
      "MAE for train: mean: 0.5621622660689025 std: 0.005593141957076557\n",
      "MAE for test: mean: 0.6806895551772036 std: 0.01935101198233509\n",
      "\n",
      "MAPE for train: mean: 0.04037138692408798 std: 0.00039818309746465964\n",
      "MAPE for test: mean: 0.048711960195761815 std: 0.001417104442500487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ex_GBR.perform_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'LR', 'param': {}}\n",
      "1.0245811562932952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.main_dataset.ensamble_model.general_Regression at 0x7102d256d9a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One can perform hyperparameter tuning on this generalized regression class. You can specify type=\"something\"\n",
    "# and it will only use parameters for that type of model, otherwise, it will randomly go through different models \n",
    "# and their corresponding parameters.\n",
    "\n",
    "ex_hp = em.hyperparameter_tuning_general(train,n_iter=10,cv=3,model=em.general_Regression,scale='log',beta=1,type=None)\n",
    "\n",
    "# Perform the tuning\n",
    "ex_hp.perform_tuning()\n",
    "\n",
    "# Outputs the best parameters it found and the score.\n",
    "print(ex_hp.best_params)\n",
    "print(ex_hp.best_score)\n",
    "\n",
    "# This is the best model it found, this is a general_Regression class if model=em.general_Regression, otherwise\n",
    "# it will be any model that is inherited from general_Regression.\n",
    "ex_hp.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models for each position\n",
    "\n",
    "#goalkeeper position model\n",
    "g_pos = em.G_Pos(train,type='LR',scale='log')\n",
    "\n",
    "# defender position model\n",
    "d_pos = em.D_Pos(train,type='RIDGE',scale='log',alpha=4)\n",
    "\n",
    "# Midfielder position model\n",
    "m_pos = em.M_Pos(train,type='RFR',scale='log',max_depth=4,n_estimators=20,min_sample_leaf=2 ,bootstrap=True)\n",
    "\n",
    "# Forward position model\n",
    "f_pos = em.F_Pos(train,type='GBR',scale='log',max_depth=4,n_estimators=20,min_sample_leaf=2 ,bootstrap=True)\n",
    "\n",
    "# Since these are inherited classes, they have the same methods as general_Regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 0.8515214668419132 std: 0.012996531669017411\n",
      "MSE for test:  mean: 1.0980076650651118  std: 0.03560443116746653\n",
      "\n",
      "RMSE for train: mean: 0.9227523605542437 std: 0.007039029299860132\n",
      "RMSE for test: mean: 1.0477215352064129 std: 0.016948443286301674\n",
      "\n",
      "R^2 for train: mean: 0.5643353543880675 std: 0.005804220110990079\n",
      "R^2 for test: mean: 0.43820396111581 std: 0.011712225418961034\n",
      "\n",
      "MAE for train: mean: 0.7037536273794515 std: 0.005842218384848044\n",
      "MAE for test: mean: 0.820043095535732 std: 0.010444179726335347\n",
      "\n",
      "MAPE for train: mean: 0.05045368600354032 std: 0.00040881041433830256\n",
      "MAPE for test: mean: 0.058654417427999414 std: 0.0008553844776853359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we can talk about our ensemble model, which is essentially takes in each of the position models like above\n",
    "\n",
    "en_model = em.ensamble_model(scale='log')\n",
    "\n",
    "# Put the parameters for each position\n",
    "en_model.G_parameters(type='LR')\n",
    "en_model.D_parameters(type='RIDGE',alpha=4)\n",
    "en_model.M_parameters(type='RFR',max_depth=4,n_estimators=20,min_sample_leaf=2 ,bootstrap=True)\n",
    "en_model.F_parameters(type='GBR',max_depth=4,n_estimators=20,min_sample_leaf=2 ,bootstrap=True)\n",
    "\n",
    "# Can perform cross-validation\n",
    "en_model.perform_CV(train,n_splits=5)\n",
    "\n",
    "#Fit the model\n",
    "en_model.fit(train)\n",
    "\n",
    "# Makes a predictions, but it is not scaled back\n",
    "predictions = en_model.predict(test)\n",
    "\n",
    "\n",
    "# This makes a prediction, but it scales it back to the original scale (before the ln(1+x))\n",
    "predictions_scaled_back = en_model.predict_scaled(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'G': {'model': 'LR', 'param': {}}, 'D': {'model': 'RFR', 'param': {'max_depth': 3, 'n_estimators': 10, 'max_features': 'sqrt', 'min_samples_split': 10, 'min_samples_leaf': 8, 'bootstrap': False}}, 'M': {'model': 'RIDGE', 'param': {'alpha': np.float64(3.9897959183673466)}}, 'F': {'model': 'LR', 'param': {}}}\n",
      "1.0593461921099772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.main_dataset.ensamble_model.ensamble_model at 0x710302232000>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To do hyperparameter tuning for the ensamble model, we use a specific class.  Note that beta is the penalizing constant\n",
    "\n",
    "en_hp = em.hyperparameter_tuning(train,n_iter=10,cv=3,scale='log',beta=1)\n",
    "\n",
    "# Perform the tuning\n",
    "en_hp.perform_tuning()\n",
    "\n",
    "# Outputs the best parameters it found and the score\n",
    "print(en_hp.best_params)\n",
    "print(en_hp.best_score)\n",
    "\n",
    "# This is the best model that it outputs, it is a ensemble_model class and has all the usual methods for that class\n",
    "en_hp.best_model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
