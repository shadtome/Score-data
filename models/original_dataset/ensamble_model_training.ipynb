{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ensamble_model as em\n",
    "importlib.reload(em)\n",
    "\n",
    "# Train Data\n",
    "fd = '../../data/main_data/train/train.csv'\n",
    "train = pd.read_csv(fd)\n",
    "\n",
    "# Test Data\n",
    "fd = '../../data/main_data/test/test.csv'\n",
    "test = pd.read_csv(fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a description of how the ensamble model works and what it is doing under all of the code\n",
    "\n",
    "The general object below is just a general_Regression object that can be changed to any model, like linear regression, Lasso, Ridge, decision tree, random forest, gradient boost regression.  You can also put in the parameters for these in the **kwargs argument, it will deal with it correctly with the names, for example max_depth=6 in a decision tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 0.9718164149663101 std: 0.0063425237322426746\n",
      "MSE for test:  mean: 0.9921637184791161  std: 0.056137283121666284\n",
      "\n",
      "RMSE for train: mean: 0.9858022401021957 std: 0.0032184430712350687\n",
      "RMSE for test: mean: 0.9956784978399821 std: 0.028072182284834084\n",
      "\n",
      "R^2 for train: mean: 0.4981374205877124 std: 0.0034748163489597577\n",
      "R^2 for test: mean: 0.4863840926024687 std: 0.03369637922276197\n",
      "\n",
      "MAE for train: mean: 0.7713606371136257 std: 0.0022404362480962325\n",
      "MAE for test: mean: 0.7777574257083658 std: 0.0193528801077698\n",
      "\n",
      "MAPE for train: mean: 0.05553508215855024 std: 0.00018568276535186495\n",
      "MAPE for test: mean: 0.055975024830683597 std: 0.0016292739650968886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline model, what we want to beat!\n",
    "\n",
    "general = em.general_Regression(train,type='LR', scale='log')\n",
    "general.perform_CV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position models\n",
    "The classes G_Pos, D_Pos, M_Pos, F_Pos, are inherited classes of the general_Regression model above, but specificalyly designed to take in X that only correspond to its position.   If you look at the code in ensamble_mode.py, you can see what features it has for each position, which is what it is using for its model.  Since this is inherits the code from general_Regression, it has all the features of that class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model for Goalkeepers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 1.22591402345411 std: 0.006828025727353497\n",
      "MSE for test:  mean: 1.2314295300362061  std: 0.06205934508636801\n",
      "\n",
      "RMSE for train: mean: 1.1072057193888885 std: 0.003085191508442716\n",
      "RMSE for test: mean: 1.1093485822244284 std: 0.027843368202442785\n",
      "\n",
      "R^2 for train: mean: 0.36692526251810664 std: 0.002074083260167302\n",
      "R^2 for test: mean: 0.3633141191758053 std: 0.019922672686285874\n",
      "\n",
      "MAE for train: mean: 0.8809492466319812 std: 0.0021147368907914045\n",
      "MAE for test: mean: 0.8826425924614612 std: 0.018849214847860975\n",
      "\n",
      "MAPE for train: mean: 0.06322154612302026 std: 0.00016149021925135283\n",
      "MAPE for test: mean: 0.06333693700665695 std: 0.0014310499490877196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#base line model for the G-position\n",
    "g_model = em.G_Pos(train, scale = 'log')\n",
    "g_model.perform_CV()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5440535397186607\n",
      "{'model': 'GBR', 'param': {'max_depth': 10, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 8, 'bootstrap': True}}\n"
     ]
    }
   ],
   "source": [
    "g_hp = em.hyperparameter_tuning_general(train,n_iter=100,cv=3,scale='log')\n",
    "print(g_hp.best_score)\n",
    "print(g_hp.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 0.0001265490405826083 std: 3.858145519361166e-05\n",
      "MSE for test:  mean: 1.1236305785108807  std: 0.0636715481585731\n",
      "\n",
      "RMSE for train: mean: 0.011119527144029145 std: 0.0017044520162818775\n",
      "RMSE for test: mean: 1.059607755694533 std: 0.029359539895506347\n",
      "\n",
      "R^2 for train: mean: 0.9999350009314828 std: 1.9755369084949526e-05\n",
      "R^2 for test: mean: 0.4184853441239145 std: 0.05431898051410733\n",
      "\n",
      "MAE for train: mean: 0.00690284480853718 std: 0.0010574523013200964\n",
      "MAE for test: mean: 0.8273108407811494 std: 0.018498598615182306\n",
      "\n",
      "MAPE for train: mean: 0.0005062996284798591 std: 7.748879245767376e-05\n",
      "MAPE for test: mean: 0.05928246734583968 std: 0.001140168843599241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking better model from hyperparameter tuning\n",
    "g_hp.best_model.perform_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this model is overfitting: so we need change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 0.987961258589283 std: 0.006683446288828631\n",
      "MSE for test:  mean: 1.0063665170562737  std: 0.05897083160872418\n",
      "\n",
      "RMSE for train: mean: 0.9939567128459608 std: 0.0033632689061734913\n",
      "RMSE for test: mean: 1.0027500638763334 std: 0.029305740944106325\n",
      "\n",
      "R^2 for train: mean: 0.48980112750348326 std: 0.0034804301073545238\n",
      "R^2 for test: mean: 0.47913538082648904 std: 0.03334695611751439\n",
      "\n",
      "MAE for train: mean: 0.7761123498824781 std: 0.002423170625815895\n",
      "MAE for test: mean: 0.78161709972238 std: 0.02159430280116342\n",
      "\n",
      "MAPE for train: mean: 0.05585964255073576 std: 0.00019635286940126447\n",
      "MAPE for test: mean: 0.056234200798305836 std: 0.0017530010961268998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# baseline model for the D-position\n",
    "d_model = em.D_Pos(train,scale='log')\n",
    "d_model.perform_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 0.04673264513570574 std: 0.0008085874088795808\n",
      "MSE for test:  mean: 0.6450817785114202  std: 0.03528497002399829\n",
      "\n",
      "RMSE for train: mean: 0.21616915008907012 std: 0.0018824679213261428\n",
      "RMSE for test: mean: 0.8028726433634181 std: 0.02184712910334101\n",
      "\n",
      "R^2 for train: mean: 0.9758672692336485 std: 0.000374529633579481\n",
      "R^2 for test: mean: 0.6661520461746238 std: 0.01926588172029876\n",
      "\n",
      "MAE for train: mean: 0.1522410707387417 std: 0.0010449607478465065\n",
      "MAE for test: mean: 0.6235159357771702 std: 0.014977371459057946\n",
      "\n",
      "MAPE for train: mean: 0.010976332419750842 std: 7.7191341816692e-05\n",
      "MAPE for test: mean: 0.044735220579156895 std: 0.0011421604953018671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets look at the D-position and try to make it better.\n",
    "#from hypertuning, it looks like random forest regressor works well\n",
    "\n",
    "d_hp = em.hyperparameter_tuning_general(train,n_iter=100,cv=3,scale='log')\n",
    "print(d_hp.best_params)\n",
    "print(d_hp.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_hp.best_model.perform_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 0.9843446354184389 std: 0.006599502477681914\n",
      "MSE for test:  mean: 1.0026610274759913  std: 0.058225505881492265\n",
      "\n",
      "RMSE for train: mean: 0.9921358620155323 std: 0.00332666817336718\n",
      "RMSE for test: mean: 1.000909066751958 std: 0.029018400536829497\n",
      "\n",
      "R^2 for train: mean: 0.4916687454630805 std: 0.003446101566907871\n",
      "R^2 for test: mean: 0.48105081799215926 std: 0.03304449514312531\n",
      "\n",
      "MAE for train: mean: 0.7752565200774655 std: 0.002377056734925013\n",
      "MAE for test: mean: 0.7809257187143217 std: 0.021203109052552748\n",
      "\n",
      "MAPE for train: mean: 0.05580615727370001 std: 0.00019403533453101512\n",
      "MAPE for test: mean: 0.05619175596846023 std: 0.0017327890978573774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#baseline model for the M-position\n",
    "m_model = em.M_Pos(train,scale='log')\n",
    "m_model.perform_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets improve the m-model\n",
    "m_hp = em.hyperparameter_tuning_general(train,n_iter=100,cv=3,scale='log')\n",
    "print(m_hp.best_score)\n",
    "print(m_hp.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_hp.best_model.perform_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 0.987961258589283 std: 0.006683446288828631\n",
      "MSE for test:  mean: 1.0063665170562737  std: 0.05897083160872418\n",
      "\n",
      "RMSE for train: mean: 0.9939567128459608 std: 0.0033632689061734913\n",
      "RMSE for test: mean: 1.0027500638763334 std: 0.029305740944106325\n",
      "\n",
      "R^2 for train: mean: 0.48980112750348326 std: 0.0034804301073545238\n",
      "R^2 for test: mean: 0.47913538082648904 std: 0.03334695611751439\n",
      "\n",
      "MAE for train: mean: 0.7761123498824781 std: 0.002423170625815895\n",
      "MAE for test: mean: 0.78161709972238 std: 0.02159430280116342\n",
      "\n",
      "MAPE for train: mean: 0.05585964255073576 std: 0.00019635286940126447\n",
      "MAPE for test: mean: 0.056234200798305836 std: 0.0017530010961268998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Baseline model for $F$-position\n",
    "f_model = em.F_Pos(train,scale='log')\n",
    "f_model.perform_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets improve the F-model\n",
    "f_hp = em.hyperparameter_tuning_general(train,n_iter=100,cv=3,scale='log')\n",
    "print(f_hp.best_score)\n",
    "print(f_hp.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_hp.best_model.perform_CV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ensamble model\n",
    "This is a new class that builds a model for all the positions and puts it together.  The way to set it up is as follows in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>pos</th>\n",
       "      <th>height</th>\n",
       "      <th>foot</th>\n",
       "      <th>date</th>\n",
       "      <th>market_value</th>\n",
       "      <th>adjusted_market_value</th>\n",
       "      <th>team</th>\n",
       "      <th>league</th>\n",
       "      <th>...</th>\n",
       "      <th>accuratePass</th>\n",
       "      <th>accurateLongBalls</th>\n",
       "      <th>accurateCross</th>\n",
       "      <th>accurateKeeperSweeper</th>\n",
       "      <th>expectedAssists</th>\n",
       "      <th>expectedGoals</th>\n",
       "      <th>xGChain</th>\n",
       "      <th>xGBuildup</th>\n",
       "      <th>prediction</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>noah mbamba</td>\n",
       "      <td>2005-01-04</td>\n",
       "      <td>D</td>\n",
       "      <td>187.0</td>\n",
       "      <td>right</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>14.914123</td>\n",
       "      <td>Bayer 04 Leverkusen</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>...</td>\n",
       "      <td>13.523810</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025627</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.625808</td>\n",
       "      <td>1.288315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zachary duncan</td>\n",
       "      <td>2000-05-29</td>\n",
       "      <td>M</td>\n",
       "      <td>183.0</td>\n",
       "      <td>right</td>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>12.815613</td>\n",
       "      <td>AGF</td>\n",
       "      <td>Superligaen</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.514280</td>\n",
       "      <td>0.698667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manuel neuer</td>\n",
       "      <td>1986-03-26</td>\n",
       "      <td>G</td>\n",
       "      <td>193.0</td>\n",
       "      <td>right</td>\n",
       "      <td>2024-10-19</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>15.201805</td>\n",
       "      <td>FC Bayern München</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>...</td>\n",
       "      <td>27.122881</td>\n",
       "      <td>5.411017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.495763</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.271096</td>\n",
       "      <td>0.270107</td>\n",
       "      <td>15.496563</td>\n",
       "      <td>0.294758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mickel miller</td>\n",
       "      <td>1995-12-01</td>\n",
       "      <td>M</td>\n",
       "      <td>173.0</td>\n",
       "      <td>left</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>12.429220</td>\n",
       "      <td>Plymouth Argyle</td>\n",
       "      <td>Championship</td>\n",
       "      <td>...</td>\n",
       "      <td>13.837209</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067950</td>\n",
       "      <td>0.015244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.544847</td>\n",
       "      <td>1.115626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gaetano monachello</td>\n",
       "      <td>1994-03-02</td>\n",
       "      <td>F</td>\n",
       "      <td>185.0</td>\n",
       "      <td>left</td>\n",
       "      <td>2016-05-15</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>13.991030</td>\n",
       "      <td>Atalanta</td>\n",
       "      <td>Serie A</td>\n",
       "      <td>...</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111925</td>\n",
       "      <td>0.161218</td>\n",
       "      <td>0.061587</td>\n",
       "      <td>14.019406</td>\n",
       "      <td>0.028376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9362</th>\n",
       "      <td>michael svoboda</td>\n",
       "      <td>1998-10-14</td>\n",
       "      <td>D</td>\n",
       "      <td>195.0</td>\n",
       "      <td>right</td>\n",
       "      <td>2024-10-20</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>14.220976</td>\n",
       "      <td>Venezia</td>\n",
       "      <td>Serie A</td>\n",
       "      <td>...</td>\n",
       "      <td>29.730769</td>\n",
       "      <td>2.653846</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038870</td>\n",
       "      <td>0.042371</td>\n",
       "      <td>0.117319</td>\n",
       "      <td>0.117319</td>\n",
       "      <td>14.464836</td>\n",
       "      <td>0.243859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9363</th>\n",
       "      <td>kalifa coulibaly</td>\n",
       "      <td>1991-08-20</td>\n",
       "      <td>F</td>\n",
       "      <td>197.0</td>\n",
       "      <td>right</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>14.370794</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>Ligue 1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.405941</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050634</td>\n",
       "      <td>0.219190</td>\n",
       "      <td>0.265225</td>\n",
       "      <td>0.053416</td>\n",
       "      <td>14.604443</td>\n",
       "      <td>0.233650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9364</th>\n",
       "      <td>nordin jackers</td>\n",
       "      <td>1997-09-04</td>\n",
       "      <td>G</td>\n",
       "      <td>185.0</td>\n",
       "      <td>right</td>\n",
       "      <td>2024-04-28</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>13.710151</td>\n",
       "      <td>Club Brugge KV</td>\n",
       "      <td>First Division A, Championship Round</td>\n",
       "      <td>...</td>\n",
       "      <td>20.742857</td>\n",
       "      <td>10.514286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.666569</td>\n",
       "      <td>0.043582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9365</th>\n",
       "      <td>mads kikkenborg</td>\n",
       "      <td>1999-10-06</td>\n",
       "      <td>G</td>\n",
       "      <td>197.0</td>\n",
       "      <td>right</td>\n",
       "      <td>2023-12-03</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>13.647174</td>\n",
       "      <td>Lyngby</td>\n",
       "      <td>Superligaen</td>\n",
       "      <td>...</td>\n",
       "      <td>16.488372</td>\n",
       "      <td>7.023256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.922657</td>\n",
       "      <td>0.275484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9366</th>\n",
       "      <td>kees luijckx</td>\n",
       "      <td>1986-02-10</td>\n",
       "      <td>D</td>\n",
       "      <td>190.0</td>\n",
       "      <td>right</td>\n",
       "      <td>2021-05-20</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>12.410148</td>\n",
       "      <td>Roda JC Kerkrade</td>\n",
       "      <td>Eredivisie, Relegation/Promotion Playoffs</td>\n",
       "      <td>...</td>\n",
       "      <td>40.320000</td>\n",
       "      <td>4.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.237932</td>\n",
       "      <td>0.827784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9367 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name         dob pos  height   foot        date  \\\n",
       "0            noah mbamba  2005-01-04   D   187.0  right  2024-02-03   \n",
       "1         zachary duncan  2000-05-29   M   183.0  right  2021-11-07   \n",
       "2           manuel neuer  1986-03-26   G   193.0  right  2024-10-19   \n",
       "3          mickel miller  1995-12-01   M   173.0   left  2024-04-12   \n",
       "4     gaetano monachello  1994-03-02   F   185.0   left  2016-05-15   \n",
       "...                  ...         ...  ..     ...    ...         ...   \n",
       "9362     michael svoboda  1998-10-14   D   195.0  right  2024-10-20   \n",
       "9363    kalifa coulibaly  1991-08-20   F   197.0  right  2022-05-21   \n",
       "9364      nordin jackers  1997-09-04   G   185.0  right  2024-04-28   \n",
       "9365     mads kikkenborg  1999-10-06   G   197.0  right  2023-12-03   \n",
       "9366        kees luijckx  1986-02-10   D   190.0  right  2021-05-20   \n",
       "\n",
       "      market_value  adjusted_market_value                 team  \\\n",
       "0        3000000.0              14.914123  Bayer 04 Leverkusen   \n",
       "1         300000.0              12.815613                  AGF   \n",
       "2        4000000.0              15.201805    FC Bayern München   \n",
       "3         250000.0              12.429220      Plymouth Argyle   \n",
       "4         900000.0              13.991030             Atalanta   \n",
       "...            ...                    ...                  ...   \n",
       "9362     1500000.0              14.220976              Venezia   \n",
       "9363     1500000.0              14.370794               Nantes   \n",
       "9364      900000.0              13.710151       Club Brugge KV   \n",
       "9365      800000.0              13.647174               Lyngby   \n",
       "9366      200000.0              12.410148     Roda JC Kerkrade   \n",
       "\n",
       "                                         league  ...  accuratePass  \\\n",
       "0                                    Bundesliga  ...     13.523810   \n",
       "1                                   Superligaen  ...      9.000000   \n",
       "2                                    Bundesliga  ...     27.122881   \n",
       "3                                  Championship  ...     13.837209   \n",
       "4                                       Serie A  ...      5.700000   \n",
       "...                                         ...  ...           ...   \n",
       "9362                                    Serie A  ...     29.730769   \n",
       "9363                                    Ligue 1  ...      7.405941   \n",
       "9364       First Division A, Championship Round  ...     20.742857   \n",
       "9365                                Superligaen  ...     16.488372   \n",
       "9366  Eredivisie, Relegation/Promotion Playoffs  ...     40.320000   \n",
       "\n",
       "      accurateLongBalls  accurateCross  accurateKeeperSweeper  \\\n",
       "0              0.619048       0.047619               0.000000   \n",
       "1              0.458333       0.041667               0.000000   \n",
       "2              5.411017       0.000000               0.495763   \n",
       "3              0.697674       0.418605               0.000000   \n",
       "4              0.200000       0.100000               0.000000   \n",
       "...                 ...            ...                    ...   \n",
       "9362           2.653846       0.038462               0.000000   \n",
       "9363           0.099010       0.069307               0.000000   \n",
       "9364          10.514286       0.000000               0.200000   \n",
       "9365           7.023256       0.000000               0.488372   \n",
       "9366           4.120000       0.000000               0.000000   \n",
       "\n",
       "      expectedAssists  expectedGoals   xGChain  xGBuildup  prediction  \\\n",
       "0            0.025627       0.001195  0.000000   0.000000   13.625808   \n",
       "1            0.000000       0.000000  0.000000   0.000000   13.514280   \n",
       "2            0.001084       0.000969  0.271096   0.270107   15.496563   \n",
       "3            0.067950       0.015244  0.000000   0.000000   13.544847   \n",
       "4            0.000000       0.111925  0.161218   0.061587   14.019406   \n",
       "...               ...            ...       ...        ...         ...   \n",
       "9362         0.038870       0.042371  0.117319   0.117319   14.464836   \n",
       "9363         0.050634       0.219190  0.265225   0.053416   14.604443   \n",
       "9364         0.000000       0.000000  0.000000   0.000000   13.666569   \n",
       "9365         0.000000       0.000000  0.000000   0.000000   13.922657   \n",
       "9366         0.000000       0.000000  0.000000   0.000000   13.237932   \n",
       "\n",
       "      residual  \n",
       "0     1.288315  \n",
       "1     0.698667  \n",
       "2     0.294758  \n",
       "3     1.115626  \n",
       "4     0.028376  \n",
       "...        ...  \n",
       "9362  0.243859  \n",
       "9363  0.233650  \n",
       "9364  0.043582  \n",
       "9365  0.275484  \n",
       "9366  0.827784  \n",
       "\n",
       "[9367 rows x 57 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To set up the ensamble model with your specifications we do the following:\n",
    "\n",
    "ex = em.ensamble_model(scale='log')    # this sets up the class ready to take inthe parameters and the data for fitting\n",
    "\n",
    "ex.G_parameters(type = 'LR') # put the parameters for the G model as just linear regression\n",
    "ex.D_parameters(type = 'RIDGE', alpha=5)  # puts the parameters for the D model as just linear regression with ridge regularization\n",
    "ex.F_parameters(type='RFR', max_depth=10)   # puts the forwards parameters as random forest with max depth of 10\n",
    "\n",
    "# Note that any left our parameters changes, for example M here, is left as just Linear regression\n",
    "\n",
    "# Once you set up what your model is, we can fit the data to it\n",
    "ex.fit(train)\n",
    "\n",
    "# It is now fitted to the data and read to predict things:\n",
    "result = train.copy()\n",
    "result[ex.target] = ex.scale_target(result[ex.target])\n",
    "\n",
    "result['prediction']= ex.predict(train)\n",
    "result['residual'] = abs(result[ex.target] - result['prediction'])\n",
    "\n",
    "display(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets say you want to figure out which model is the best through a cross-validation.\n",
    "You can do the above, but now you use a perform_CV(train) to do a cross-validation with the type of parameters you put in\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 0.7454830095134034 std: 0.00572234405339352\n",
      "MSE for test:  mean: 0.996919386291642  std: 0.06584344309304907\n",
      "\n",
      "RMSE for train: mean: 0.8634072224588488 std: 0.0033132641457367345\n",
      "RMSE for test: mean: 0.9979164769063393 std: 0.032895157857675425\n",
      "\n",
      "R^2 for train: mean: 0.6150215229061187 std: 0.002876980265179195\n",
      "R^2 for test: mean: 0.48434522954280174 std: 0.03141278041223129\n",
      "\n",
      "MAE for train: mean: 0.6423923594436958 std: 0.0022225905334812292\n",
      "MAE for test: mean: 0.7770604159011327 std: 0.020860191668480275\n",
      "\n",
      "MAPE for train: mean: 0.04610834073999311 std: 0.00016847813935349205\n",
      "MAPE for test: mean: 0.05583895019415822 std: 0.0015787696932722717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make the ensamble model object\n",
    "ensamble = em.ensamble_model(scale='log')\n",
    "\n",
    "ensamble.G_parameters(type = 'DT') # put the parameters for the G model as just linear regression\n",
    "ensamble.D_parameters(type = 'RIDGE', alpha=5)  # puts the parameters for the D model as just linear regression with ridge regularization\n",
    "ensamble.F_parameters(type='RFR', max_depth=10)   # puts the forwards parameters as random forest with max depth of 10\n",
    "\n",
    "ensamble.perform_CV(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 0.2895754092964745 std: 0.0049122880909785605\n",
      "MSE for test:  mean: 0.7544538816507846  std: 0.04213843955709652\n",
      "\n",
      "RMSE for train: mean: 0.5381028615146602 std: 0.004551892596368877\n",
      "RMSE for test: mean: 0.868253455109634 std: 0.02428619651092614\n",
      "\n",
      "R^2 for train: mean: 0.8504566883179487 std: 0.0026511860900081453\n",
      "R^2 for test: mean: 0.609610613484545 std: 0.021962336366659434\n",
      "\n",
      "MAE for train: mean: 0.3937592153202706 std: 0.0021538266569940453\n",
      "MAE for test: mean: 0.6783822132082473 std: 0.01645014332380803\n",
      "\n",
      "MAPE for train: mean: 0.02838953346982533 std: 0.0001657208639421521\n",
      "MAPE for test: mean: 0.048613288823953514 std: 0.001302318254336439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ex = em.ensamble_model(scale='log')\n",
    "ex.G_parameters(type ='DT',max_depth = 3, max_features = 0.75, min_samples_split = 5, min_samples_leaf=4)\n",
    "ex.D_parameters(type ='RFR', max_depth= 10, n_estimators= 100, max_features= 'sqrt', min_samples_split= 10,\n",
    "                 min_samples_leaf=2, bootstrap= False )\n",
    "ex.M_parameters(type='RFR',max_depth=None, n_estimators= 200, max_features= 0.25, min_samples_split= 5,\n",
    "                 min_samples_leaf=1, bootstrap= True)\n",
    "ex.F_parameters(type = 'RFR',max_depth= 10, n_estimators= 10, max_features= 0.5, min_samples_split= 2,\n",
    "                 min_samples_leaf= 4, bootstrap=True)\n",
    "ex.perform_CV(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "This takes in the set of possible parameters defined in the ensamble_model.py and randomly chooses them as it goes through the n_iter=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'G': {'model': 'KNN', 'param': {'n_neighbors': 6}}, 'D': {'model': 'RFR', 'param': {'max_depth': None, 'n_estimators': 50, 'max_features': 0.5, 'min_samples_split': 10, 'min_samples_leaf': 1, 'bootstrap': False}}, 'M': {'model': 'RFR', 'param': {'max_depth': 10, 'n_estimators': 20, 'max_features': 0.75, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': True}}, 'F': {'model': 'GBR', 'param': {'max_depth': 5, 'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 7, 'bootstrap': False}}}\n",
      "0.9097402676223301\n",
      "<ensamble_model.ensamble_model object at 0x76d3c16d2ff0>\n"
     ]
    }
   ],
   "source": [
    "# Lets try some hyperparameter tuning:\n",
    "\n",
    "hp = em.hyperparameter_tuning(train,n_iter=1000,cv=4)\n",
    "\n",
    "# After it gets done doing its hyperparameter tuning, it saves the best model, the parameters for that model, and the score \n",
    "# (which is just RMSE for now, I can change it later to do what ever score you want to use)\n",
    "\n",
    "print(hp.best_params)  # Best parameters in a dictionary object\n",
    "print(hp.best_score)   # the best RMSE\n",
    "print(hp.best_model)   # the ensamble_model() object that has the best parameters above and score.\n",
    "\n",
    "# You can now use the hp.best_model to do predictions and we can save it later once we have the one we want.\n",
    "\n",
    "# you can now do \n",
    "best_model_prediction = hp.best_model.predict(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train: mean: 0.18186342164730637 std: 0.0018113113554112945\n",
      "MSE for test:  mean: 0.8201073298117496  std: 0.04687169637008292\n",
      "\n",
      "RMSE for train: mean: 0.42644918521680386 std: 0.002124635317064425\n",
      "RMSE for test: mean: 0.9052201114094249 std: 0.026151093890267766\n",
      "\n",
      "R^2 for train: mean: 0.9060828984349527 std: 0.0009341586927974755\n",
      "R^2 for test: mean: 0.5754906654398151 std: 0.02648926449754054\n",
      "\n",
      "MAE for train: mean: 0.25899913440105615 std: 0.001670153125031759\n",
      "MAE for test: mean: 0.6985663339637462 std: 0.02059325913710562\n",
      "\n",
      "MAPE for train: mean: 0.01865477591382816 std: 0.00012833621135423424\n",
      "MAPE for test: mean: 0.050136511865538205 std: 0.0014348098122654064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hp.best_model.perform_CV(train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
